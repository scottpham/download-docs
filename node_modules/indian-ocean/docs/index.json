[
  {
    "description": "",
    "tags": [
      {
        "title": "namespace",
        "description": null,
        "lineNumber": 0,
        "name": null
      },
      {
        "title": "name",
        "name": "helpers"
      },
      {
        "title": "kind",
        "kind": "namespace"
      }
    ],
    "loc": {
      "start": {
        "line": 30,
        "column": 0
      },
      "end": {
        "line": 30,
        "column": 17
      }
    },
    "context": {
      "loc": {
        "start": {
          "line": 31,
          "column": 0
        },
        "end": {
          "line": 41,
          "column": 0
        }
      },
      "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
      "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
      "path": "lib/index.js",
      "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L31-L41"
    },
    "name": "helpers",
    "kind": "namespace",
    "members": {
      "instance": [],
      "static": [
        {
          "description": "Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 2,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "returns",
              "description": "a formatter that can write the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            },
            {
              "title": "example",
              "description": "var formatter = io.discernFileFormatter('path/to/data.tsv');\nvar csv = formatter(json);",
              "lineNumber": 5
            },
            {
              "title": "name",
              "name": "discernFileFormatter"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "helpers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 67,
              "column": 0
            },
            "end": {
              "line": 75,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 76,
                "column": 0
              },
              "end": {
                "line": 82,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L76-L82"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 2,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "a formatter that can write the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            }
          ],
          "examples": [
            "<span class=\"hljs-keyword\">var</span> formatter = io.discernFileFormatter(<span class=\"hljs-string\">'path/to/data.tsv'</span>);\n<span class=\"hljs-keyword\">var</span> csv = formatter(json);"
          ],
          "name": "discernFileFormatter",
          "kind": "function",
          "memberof": "helpers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "helpers",
            "discernFileFormatter"
          ]
        },
        {
          "description": "Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 2,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "returns",
              "description": "the file's extension",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              }
            },
            {
              "title": "example",
              "description": "io.discernFormat('path/to/data.csv') -> 'csv'",
              "lineNumber": 5
            },
            {
              "title": "name",
              "name": "discernFormat"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "helpers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 33,
              "column": 0
            },
            "end": {
              "line": 40,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 41,
                "column": 0
              },
              "end": {
                "line": 61,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L41-L61"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 2,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the file's extension",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              }
            }
          ],
          "examples": [
            "io.discernFormat(<span class=\"hljs-string\">'path/to/data.csv'</span>) -&gt; <span class=\"hljs-string\">'csv'</span>"
          ],
          "name": "discernFormat",
          "kind": "function",
          "memberof": "helpers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "helpers",
            "discernFormat"
          ]
        },
        {
          "description": "Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 2,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "optional delimiter",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "delimiter"
            },
            {
              "title": "returns",
              "description": "a parser that can read the file",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            },
            {
              "title": "example",
              "description": "var parser = io.discernParser('path/to/data.csv');\nvar json = parser('path/to/data.csv');",
              "lineNumber": 6
            },
            {
              "title": "name",
              "name": "discernParser"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "helpers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 51,
              "column": 0
            },
            "end": {
              "line": 60,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 61,
                "column": 0
              },
              "end": {
                "line": 76,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L61-L76"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 2,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "optional delimiter",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "delimiter"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "a parser that can read the file",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            }
          ],
          "examples": [
            "<span class=\"hljs-keyword\">var</span> parser = io.discernParser(<span class=\"hljs-string\">'path/to/data.csv'</span>);\n<span class=\"hljs-keyword\">var</span> json = parser(<span class=\"hljs-string\">'path/to/data.csv'</span>);"
          ],
          "name": "discernParser",
          "kind": "function",
          "memberof": "helpers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "helpers",
            "discernParser"
          ]
        }
      ]
    },
    "events": [],
    "path": [
      "helpers"
    ]
  },
  {
    "description": "",
    "tags": [
      {
        "title": "namespace",
        "description": null,
        "lineNumber": 0,
        "name": null
      },
      {
        "title": "name",
        "name": "readers"
      },
      {
        "title": "kind",
        "kind": "namespace"
      }
    ],
    "loc": {
      "start": {
        "line": 81,
        "column": 0
      },
      "end": {
        "line": 81,
        "column": 17
      }
    },
    "context": {
      "loc": {
        "start": {
          "line": 82,
          "column": 0
        },
        "end": {
          "line": 100,
          "column": 0
        }
      },
      "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
      "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
      "path": "lib/index.js",
      "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L82-L100"
    },
    "name": "readers",
    "kind": "namespace",
    "members": {
      "instance": [],
      "static": [
        {
          "description": "Asynchronously read a comma-separated value file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readCsv"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 119,
              "column": 0
            },
            "end": {
              "line": 124,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 125,
                "column": 0
              },
              "end": {
                "line": 137,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L125-L137"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readCsv",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readCsv"
          ]
        },
        {
          "description": "Synchronously read a comma-separated value file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            },
            {
              "title": "name",
              "name": "readCsvSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 131,
              "column": 0
            },
            "end": {
              "line": 136,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 137,
                "column": 0
              },
              "end": {
                "line": 147,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L137-L147"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            }
          ],
          "name": "readCsvSync",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readCsvSync"
          ]
        },
        {
          "description": "Asynchronously read data given a path ending in the file format.\n\nSupported formats:\n\n* `.json` Array of objects\n* `.csv` Comma-separated\n* `.tsv` Tab-separated\n* `.psv` Pipe-separated\n\n*Note: Does not currently support .dbf files.*",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 12,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "optional delimiter to use when reading the file",
              "lineNumber": 13,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "delimiter"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 14,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readData"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 84,
              "column": 0
            },
            "end": {
              "line": 99,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 100,
                "column": 0
              },
              "end": {
                "line": 115,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L100-L115"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 12,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "optional delimiter to use when reading the file",
              "lineNumber": 13,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "delimiter"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 14,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readData",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readData"
          ]
        },
        {
          "description": "Syncronous version of {@link readers#readData}",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "optional delimiter to use when reading the file",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "delimiter"
            },
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            },
            {
              "title": "name",
              "name": "readDataSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 108,
              "column": 0
            },
            "end": {
              "line": 114,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 115,
                "column": 0
              },
              "end": {
                "line": 125,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L115-L125"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "optional delimiter to use when reading the file",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "delimiter"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            }
          ],
          "name": "readDataSync",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readDataSync"
          ]
        },
        {
          "description": "Asynchronously read a dbf file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readDbf"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 207,
              "column": 0
            },
            "end": {
              "line": 212,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 213,
                "column": 0
              },
              "end": {
                "line": 270,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L213-L270"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readDbf",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readDbf"
          ]
        },
        {
          "description": "Asynchronously read a JSON file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readJson"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 141,
              "column": 0
            },
            "end": {
              "line": 146,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 147,
                "column": 0
              },
              "end": {
                "line": 159,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L147-L159"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readJson",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readJson"
          ]
        },
        {
          "description": "Synchronously read a JSON file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            },
            {
              "title": "name",
              "name": "readJsonSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 153,
              "column": 0
            },
            "end": {
              "line": 158,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 159,
                "column": 0
              },
              "end": {
                "line": 169,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L159-L169"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            }
          ],
          "name": "readJsonSync",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readJsonSync"
          ]
        },
        {
          "description": "Asynchronously read a pipe-separated value file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readPsv"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 185,
              "column": 0
            },
            "end": {
              "line": 190,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 191,
                "column": 0
              },
              "end": {
                "line": 203,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L191-L203"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readPsv",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readPsv"
          ]
        },
        {
          "description": "Synchronously read a pipe-separated value file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            },
            {
              "title": "name",
              "name": "readPsvSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 197,
              "column": 0
            },
            "end": {
              "line": 202,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 203,
                "column": 0
              },
              "end": {
                "line": 213,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L203-L213"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            }
          ],
          "name": "readPsvSync",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readPsvSync"
          ]
        },
        {
          "description": "Asynchronously read a tab-separated value file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readTsv"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 163,
              "column": 0
            },
            "end": {
              "line": 168,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 169,
                "column": 0
              },
              "end": {
                "line": 181,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L169-L181"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "callback used when read data is read, takes error (if any) and the data read",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readTsv",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readTsv"
          ]
        },
        {
          "description": "Synchronously read a tab-separated value file.",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            },
            {
              "title": "name",
              "name": "readTsvSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 175,
              "column": 0
            },
            "end": {
              "line": 180,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 181,
                "column": 0
              },
              "end": {
                "line": 191,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L181-L191"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the contents of the file as JSON",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              }
            }
          ],
          "name": "readTsvSync",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readTsvSync"
          ]
        },
        {
          "description": "Get a list of the files in a directory that do not have the selected extentions.",
          "tags": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            },
            {
              "title": "param",
              "description": "the callback that will accept the filtered files, takes an optional error and an array of file names",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readdirExclude"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 310,
              "column": 0
            },
            "end": {
              "line": 316,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 317,
                "column": 0
              },
              "end": {
                "line": 336,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L317-L336"
          },
          "params": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            },
            {
              "title": "param",
              "description": "the callback that will accept the filtered files, takes an optional error and an array of file names",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readdirExclude",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readdirExclude"
          ]
        },
        {
          "description": "Synchronously get a list of the files in a directory that do not have the selected extentions.",
          "tags": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            },
            {
              "title": "returns",
              "description": "the matching files' paths",
              "lineNumber": 5,
              "type": {
                "type": "TypeApplication",
                "expression": {
                  "type": "NameExpression",
                  "name": "Array"
                },
                "applications": [
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              }
            },
            {
              "title": "name",
              "name": "readdirExcludeSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 329,
              "column": 0
            },
            "end": {
              "line": 335,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 336,
                "column": 0
              },
              "end": {
                "line": 346,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L336-L346"
          },
          "params": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the matching files' paths",
              "lineNumber": 5,
              "type": {
                "type": "TypeApplication",
                "expression": {
                  "type": "NameExpression",
                  "name": "Array"
                },
                "applications": [
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              }
            }
          ],
          "name": "readdirExcludeSync",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readdirExcludeSync"
          ]
        },
        {
          "description": "Get a list of the files in a directory with selected extentions.",
          "tags": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            },
            {
              "title": "param",
              "description": "the callback that will accept the filtered files, takes an optional error and an array of file names",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "readdirInclude"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 275,
              "column": 0
            },
            "end": {
              "line": 281,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 282,
                "column": 0
              },
              "end": {
                "line": 301,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L282-L301"
          },
          "params": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            },
            {
              "title": "param",
              "description": "the callback that will accept the filtered files, takes an optional error and an array of file names",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "readdirInclude",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readdirInclude"
          ]
        },
        {
          "description": "Synchronously get a list of the files in a directory with selected extentions.",
          "tags": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            },
            {
              "title": "returns",
              "description": "the matching files' paths",
              "lineNumber": 5,
              "type": {
                "type": "TypeApplication",
                "expression": {
                  "type": "NameExpression",
                  "name": "Array"
                },
                "applications": [
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              }
            },
            {
              "title": "name",
              "name": "readdirIncludeSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "readers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 294,
              "column": 0
            },
            "end": {
              "line": 300,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 301,
                "column": 0
              },
              "end": {
                "line": 317,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L301-L317"
          },
          "params": [
            {
              "title": "param",
              "description": "the directory to read from",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "path"
            },
            {
              "title": "param",
              "description": "the file extention(s) to include",
              "lineNumber": 4,
              "type": {
                "type": "UnionType",
                "elements": [
                  {
                    "type": "TypeApplication",
                    "expression": {
                      "type": "NameExpression",
                      "name": "Array"
                    },
                    "applications": [
                      {
                        "type": "NameExpression",
                        "name": "String"
                      }
                    ]
                  },
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              },
              "name": "includes"
            }
          ],
          "returns": [
            {
              "title": "returns",
              "description": "the matching files' paths",
              "lineNumber": 5,
              "type": {
                "type": "TypeApplication",
                "expression": {
                  "type": "NameExpression",
                  "name": "Array"
                },
                "applications": [
                  {
                    "type": "NameExpression",
                    "name": "String"
                  }
                ]
              }
            }
          ],
          "name": "readdirIncludeSync",
          "kind": "function",
          "memberof": "readers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "readers",
            "readdirIncludeSync"
          ]
        }
      ]
    },
    "events": [],
    "path": [
      "readers"
    ]
  },
  {
    "description": "",
    "tags": [
      {
        "title": "namespace",
        "description": null,
        "lineNumber": 0,
        "name": null
      },
      {
        "title": "name",
        "name": "writers"
      },
      {
        "title": "kind",
        "kind": "namespace"
      }
    ],
    "loc": {
      "start": {
        "line": 345,
        "column": 0
      },
      "end": {
        "line": 345,
        "column": 17
      }
    },
    "context": {
      "loc": {
        "start": {
          "line": 346,
          "column": 0
        },
        "end": {
          "line": 364,
          "column": 0
        }
      },
      "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
      "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
      "path": "lib/index.js",
      "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L346-L364"
    },
    "name": "writers",
    "kind": "namespace",
    "members": {
      "instance": [],
      "static": [
        {
          "description": "Append to an existing data object, creating a new file if one does not exist\n\nSupported formats:\n\n* `.json` Array of objects\n* `.csv` Comma-separated\n* `.tsv` Tab-separated\n* `.psv` Pipe-separated\n\n*Note: Does not currently support .dbf files.*",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 12,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 13,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            },
            {
              "title": "param",
              "description": "callback that takes an error, if any",
              "lineNumber": 14,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "appendData"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "writers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 382,
              "column": 0
            },
            "end": {
              "line": 397,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 398,
                "column": 0
              },
              "end": {
                "line": 423,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L398-L423"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 12,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 13,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            },
            {
              "title": "param",
              "description": "callback that takes an error, if any",
              "lineNumber": 14,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "appendData",
          "kind": "function",
          "memberof": "writers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "writers",
            "appendData"
          ]
        },
        {
          "description": "Synchronous version of {@link writers#appendData}",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            },
            {
              "title": "name",
              "name": "appendDataSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "writers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 417,
              "column": 0
            },
            "end": {
              "line": 422,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 423,
                "column": 0
              },
              "end": {
                "line": 439,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L423-L439"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            }
          ],
          "name": "appendDataSync",
          "kind": "function",
          "memberof": "writers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "writers",
            "appendDataSync"
          ]
        },
        {
          "description": "Write the data object, inferring the file format from the file ending specified in `fileName`.\n\nSupported formats:\n\n* `.json` Array of objects\n* `.csv` Comma-separated\n* `.tsv` Tab-separated\n* `.psv` Pipe-separated\n\n*Note: Does not currently support .dbf files.*",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 12,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 13,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            },
            {
              "title": "param",
              "description": "callback that takes an error, if any",
              "lineNumber": 14,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "writeData"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "writers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 348,
              "column": 0
            },
            "end": {
              "line": 363,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 364,
                "column": 0
              },
              "end": {
                "line": 377,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L364-L377"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 12,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 13,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            },
            {
              "title": "param",
              "description": "callback that takes an error, if any",
              "lineNumber": 14,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "writeData",
          "kind": "function",
          "memberof": "writers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "writers",
            "writeData"
          ]
        },
        {
          "description": "Syncronous version of {@link writers#writeData}",
          "tags": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            },
            {
              "title": "name",
              "name": "writeDataSync"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "writers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 371,
              "column": 0
            },
            "end": {
              "line": 376,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 377,
                "column": 0
              },
              "end": {
                "line": 398,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L377-L398"
          },
          "params": [
            {
              "title": "param",
              "description": "the name of the file",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "fileName"
            },
            {
              "title": "param",
              "description": "the data to write",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "Object"
              },
              "name": "data"
            }
          ],
          "name": "writeDataSync",
          "kind": "function",
          "memberof": "writers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "writers",
            "writeDataSync"
          ]
        },
        {
          "description": "Reads in a dbf file with `.readDbf` and write to file using `.writeData`.",
          "tags": [
            {
              "title": "param",
              "description": "the input file name",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "inFileName"
            },
            {
              "title": "param",
              "description": "the output file name",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "outFileName"
            },
            {
              "title": "param",
              "description": "callback that takes error (if any)",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            },
            {
              "title": "name",
              "name": "writeDbfToData"
            },
            {
              "title": "kind",
              "kind": "function"
            },
            {
              "title": "memberof",
              "description": "writers"
            },
            {
              "title": "static"
            }
          ],
          "loc": {
            "start": {
              "line": 432,
              "column": 0
            },
            "end": {
              "line": 438,
              "column": 3
            }
          },
          "context": {
            "loc": {
              "start": {
                "line": 439,
                "column": 0
              },
              "end": {
                "line": 449,
                "column": 0
              }
            },
            "file": "/Users/michael.keller/wrk/code/indian-ocean/lib/index.js",
            "code": "var fs = require('fs')\nvar dsv = require('d3-dsv')\nvar dbf = require('shapefile/dbf')\nvar path = require('path')\nvar queue = require('queue-async')\nvar _ = require('underscore')\n\nvar formatters = {\n  json: function (file) {\n    return JSON.stringify(file)\n  },\n  csv: function (file) {\n    return dsv.csv.format(file)\n  },\n  tsv: function (file) {\n    return dsv.tsv.format(file)\n  },\n  psv: function (file) {\n    return dsv.dsv('|').format(file)\n  }\n}\n\nvar parsers = {\n  json: JSON,\n  csv: dsv.csv,\n  tsv: dsv.tsv,\n  psv: dsv.dsv('|')\n}\n\n/** @namespace */\nvar helpers = {}\n\n/**\n * Given a `fileName` return its file extension. Used internally by `.discernPaser` and `.discernFileFormatter`.\n * @param {String} fileName the name of the file\n * @returns {String} the file's extension\n *\n * @example\n * io.discernFormat('path/to/data.csv') -> 'csv'\n */\nhelpers.discernFormat = function (fileName) {\n  var extension = path.extname(fileName)\n  if (extension === '') return false\n\n  var formatName = extension.slice(1)\n  // If it ends in json such as `topojson` or `geojson`, call it json.\n  if (formatName.substr(formatName.length - 4) === 'json') formatName = 'json'\n  return formatName\n}\n\n/**\n * Given a `fileName`, optionally a delimiter, return a parser that can read that file as json. Used internally by `.readData` and `.readDataSync`.\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter\n * @returns {Object} a parser that can read the file\n *\n * @example\n * var parser = io.discernParser('path/to/data.csv');\n * var json = parser('path/to/data.csv');\n */\nhelpers.discernParser = function (fileName, delimiter) {\n  if (delimiter) return dsv.dsv(delimiter)\n  var format = helpers.discernFormat(fileName)\n  return parsers[format]\n}\n\n/**\n * Returns a formatter that will format json data to file type specified by the extension in `fileName`. Used internally by `.writeData` and `.writeDataSync`.\n * @param {String} fileName the name of the file\n * @returns {Object} a formatter that can write the file\n *\n * @example\n * var formatter = io.discernFileFormatter('path/to/data.tsv');\n * var csv = formatter(json);\n */\nhelpers.discernFileFormatter = function (fileName) {\n  var format = helpers.discernFormat(fileName)\n  return formatters[format]\n}\n\n/** @namespace */\nvar readers = {}\n\n/**\n * Asynchronously read data given a path ending in the file format.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readData = function (path, delimiter_, cb_) {\n  var cb = arguments[arguments.length - 1]\n  var delimiter = arguments.length === 3 ? delimiter : false\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, helpers.discernParser(path, delimiter).parse(data))\n  })\n}\n\n/**\n * Syncronous version of {@link readers#readData}\n *\n * @param {String} fileName the name of the file\n * @param {String} delimiter optional delimiter to use when reading the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readDataSync = function (path, delimiter) {\n  return helpers.discernParser(path, delimiter).parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readCsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.csv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a comma-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readCsvSync = function (path) {\n  return parsers.csv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readJson = function (path, cb) {\n  fs.readFile(path, function (err, data) {\n    cb(err, JSON.parse(data))\n  })\n}\n\n/**\n * Synchronously read a JSON file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readJsonSync = function (path) {\n  return parsers.json.parse(fs.readFileSync(path))\n}\n\n/**\n * Asynchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readTsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.tsv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a tab-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readTsvSync = function (path) {\n  return parsers.tsv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readPsv = function (path, cb) {\n  fs.readFile(path, 'utf8', function (err, data) {\n    cb(err, parsers.psv.parse(data))\n  })\n}\n\n/**\n * Synchronously read a pipe-separated value file.\n *\n * @param {String} fileName the name of the file\n * @returns {Object} the contents of the file as JSON\n */\nreaders.readPsvSync = function (path) {\n  return parsers.psv.parse(fs.readFileSync(path, 'utf8'))\n}\n\n/**\n * Asynchronously read a dbf file.\n *\n * @param {String} fileName the name of the file\n * @param {Function} callback callback used when read data is read, takes error (if any) and the data read\n */\nreaders.readDbf = function (path, cb) {\n  var reader = dbf.reader(path)\n  var rows = []\n  var headers\n\n  // Run these in order\n  queue(1)\n    .defer(readHeader)\n    .defer(readAllRecords)\n    .defer(close)\n    .await(function (error, readHeaderData, readAllRecordsData, jsonData) {\n      // We're using queue to work through this flow\n      // As a result, `readHeaderData`, `readAllRecordsData` are going to be undefined\n      // Because they aren't meant to return anything, just process data\n      // `rowData`, however contains all our concatenated data, so let's return that\n      cb(error, jsonData)\n    })\n\n  function readHeader (callback) {\n    reader.readHeader(function (error, header) {\n      if (error) {\n        return callback(error)\n      }\n      headers = header.fields.map(function (d) {\n        return d.name\n      })\n      callback(null)\n    })\n  }\n\n  function readAllRecords (callback) {\n    (function readRecord () {\n      reader.readRecord(function (error, record) {\n        if (error) {\n          return callback(error)\n        }\n        if (record === dbf.end) {\n          return callback(null)\n        }\n        var jsonRecord = _.object(headers, record)\n        rows.push(jsonRecord)\n        process.nextTick(readRecord)\n      })\n    })()\n  }\n\n  function close (callback) {\n    reader.close(function (error) {\n      if (error) {\n        return callback(error)\n      }\n      callback(null, rows)\n    })\n  }\n\n}\n\nfunction extensionMatches (file, extension) {\n  // Chop '.' off extension returned by extname\n  return path.extname(file).slice(1) === extension\n}\n\n/**\n * Get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirInclude = function (path, includes, cb) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory with selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirIncludeSync = function (path, includes) {\n  if (typeof includes === 'string') {\n    includes = [includes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(includes, function (includeExtension) { return extensionMatches(file, includeExtension) })\n  })\n}\n\n/**\n * Get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @param {Function} callback the callback that will accept the filtered files, takes an optional error and an array of file names\n */\nreaders.readdirExclude = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  fs.readdir(path, function (err, files) {\n    var filtered = files.filter(function (file) {\n      return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n    })\n    cb(err, filtered)\n  })\n}\n\n/**\n * Synchronously get a list of the files in a directory that do not have the selected extentions.\n *\n * @param {String} path the directory to read from\n * @param {Array<String>|String} includes the file extention(s) to include\n * @returns {Array<String>} the matching files' paths\n */\nreaders.readdirExcludeSync = function (path, excludes, cb) {\n  if (typeof excludes === 'string') {\n    excludes = [excludes]\n  }\n  return fs.readdirSync(path).filter(function (file) {\n    return _.some(excludes, function (excludeExtension) { return !extensionMatches(file, excludeExtension) })\n  })\n}\n\n/** @namespace */\nvar writers = {}\n\n/**\n * Write the data object, inferring the file format from the file ending specified in `fileName`.\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.writeData = function (path, data, cb) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFile(path, fileFormatter(data), function (err) {\n    cb(err)\n  })\n}\n\n/**\n * Syncronous version of {@link writers#writeData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.writeDataSync = function (path, data) {\n  var fileFormatter = helpers.discernFileFormatter(path)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Append to an existing data object, creating a new file if one does not exist\n *\n * Supported formats:\n *\n * * `.json` Array of objects\n * * `.csv` Comma-separated\n * * `.tsv` Tab-separated\n * * `.psv` Pipe-separated\n *\n * *Note: Does not currently support .dbf files.*\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n * @param {Function} callback callback that takes an error, if any\n */\nwriters.appendData = function (path, data, cb) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFile(path, '', function (err) {\n    if (!err) {\n      readers.readData(path, function (err, existingData) {\n        if (!err) {\n          var fileFormatter = helpers.discernFileFormatter(path)\n          data = existingData.concat(data)\n          fs.writeFile(path, fileFormatter(data), cb)\n        } else {\n          cb(err)\n        }\n      })\n    } else {\n      cb(err)\n    }\n  })\n}\n\n/**\n * Synchronous version of {@link writers#appendData}\n *\n * @param {String} fileName the name of the file\n * @param {Object} data the data to write\n */\nwriters.appendDataSync = function (path, data) {\n  // Run append file to delegate creating a new file if none exists\n  fs.appendFileSync(path, '')\n  var existingData = readers.readDataSync(path)\n  var fileFormatter = helpers.discernFileFormatter(path)\n  data = existingData.concat(data)\n  fs.writeFileSync(path, fileFormatter(data))\n}\n\n/**\n * Reads in a dbf file with `.readDbf` and write to file using `.writeData`.\n *\n * @param {String} inFileName the input file name\n * @param {String} outFileName the output file name\n * @param {Function} callback callback that takes error (if any)\n */\nwriters.writeDbfToData = function (inPath, outPath, cb) {\n  readers.readDbf(inPath, function (error, jsonData) {\n    if (error) {\n      cb(error)\n    } else {\n      writers.writeData(outPath, jsonData, cb)\n    }\n  })\n}\n\nmodule.exports = _.extend({}, readers, writers, helpers, { fs: fs })\n",
            "path": "lib/index.js",
            "github": "https://github.com/mhkeller/indian-ocean/blob/b47f1228175d361c00be837bf9c027c3da34d49c/lib/index.js#L439-L449"
          },
          "params": [
            {
              "title": "param",
              "description": "the input file name",
              "lineNumber": 3,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "inFileName"
            },
            {
              "title": "param",
              "description": "the output file name",
              "lineNumber": 4,
              "type": {
                "type": "NameExpression",
                "name": "String"
              },
              "name": "outFileName"
            },
            {
              "title": "param",
              "description": "callback that takes error (if any)",
              "lineNumber": 5,
              "type": {
                "type": "NameExpression",
                "name": "Function"
              },
              "name": "callback"
            }
          ],
          "name": "writeDbfToData",
          "kind": "function",
          "memberof": "writers",
          "scope": "static",
          "members": {
            "instance": [],
            "static": []
          },
          "events": [],
          "path": [
            "writers",
            "writeDbfToData"
          ]
        }
      ]
    },
    "events": [],
    "path": [
      "writers"
    ]
  }
]